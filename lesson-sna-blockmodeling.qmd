# Blockmodeling

```{r setup, include=FALSE}
    library(ggraph)
    library(tidygraph)
    library(igraph)
    library(kableExtra)
    library(corrplot)

    #function:
    corr.dist <- function(x) {
         r <- nrow(x)
         c <- ncol(x)
         r.c <- matrix(0, r, r)
         c.c <- matrix(0, c, c)
         r.m <- rowMeans(x)
         c.m <- colMeans(x)
         
         for (i in 1: r) {
              for (j in 1:r) {
                   r.x <- x[i, ] - r.m[i]
                   r.y <- x[j, ] - r.m[j]
                   r.xy <- r.x * r.y
                   r.xx <- r.x^2
                   r.yy <- r.y^2
                   r.num <- sum(r.xy)
                   r.den <- sqrt(sum(r.xx)) * sqrt(sum(r.yy))
                   r.c[i, j] <- round(r.num / r.den, 2)
              }
         }
         rownames(r.c) <- rownames(x)
         colnames(r.c) <- rownames(x)
         return(r.c)
        }
```

## The Correlation Distance

It turns out there is an even fancier way to find out whether two nodes in a graph are structurally similar. It relies on a more complicated measure of distance called **the correlation distance**. This measure compares the row (or column) vectors of nodes in a graph and returns a number between $-1$ and $+1$. When it comes to structural equivalence, the correlation distance works like this:

-   Pairs of structurally equivalent nodes get a $+1$. Nodes that are *almost* structurally equivalent but not quite (they are structurally similar) get a positive number larger than zero. The closer that number is to $+1$ the more structurally similar the two nodes are.
-   Nodes that are *completely different* from one another (that is connect to completely **disjoint** sets of neighbors) get a $-1$. In this case, nodes are opposites: Every time one node *i* has a $1$ in their row vector in the adjacency matrix, the other has a $0$ and vice versa. Nodes that are structurally *dissimilar* thus get a negative number between zero and $-1$. The closer that number is to $-1$, the more structurally dissimilar the two nodes are.
-   Nodes that have an even combination of similarities and differences in their pattern of connectivity to others get a number close to zero, with $0$ indicating that two nodes have an even number of commonalities and differences.

The correlation distance between two nodes *k* and *l* is computed using the following formula:

$$
    d^{corr}_{k, l} = 
    \frac{
    \sum_j
    (a_{(k)j} - \overline{a}_{(k)j}) \times
    (a_{(l)j} - \overline{a}_{(l)j})
    }
    {
    \sqrt{
    \sum_j
    (a_{(k)j} - \overline{a}_{(k)j})^2 \times
    \sum_j
    (a_{(l)j} - \overline{a}_{(l)j})^2
        }
    }
$$ {#eq-cor}

@eq-cor looks like a monstrously complicated one, but it is actually not that involved.

Let's go through each components that we have already encountered in the lesson structural equivalence and structural similarity:

-   $a_{(k)j}$ is the row (or column) vector for node *k* in the adjacency matrix.
-   $a_{(l)j}$ is the row (or column) vector for node *l* in the adjacency matrix.

Now let's introduce ourselves to some new friends. For instance, what the heck is $\overline{a}_{(k)j}$? The little "bar" on top the $a$ indicates that we are taking the **mean** or the **average** of the elements of the row vector.

In equation form:

$$
\overline{a}_{(k)j} = \frac{\sum_j a_{kj}}{N}
$$ {#eq-avg}

In @eq-avg, $\sum_i a_{kj}$ is the sum of all the elements in the vector, and $N$ is the **length** of the vector, which is equivalent to the **order** of the graph from which adjacency matrix came from (the number of nodes in the network).

So for instance, in @tbl-adjmat1, the row vector for node *A* is:

```{r}
#| label: tbl-rowvecA
#| tbl-cap: Row vector for node A.

    a <- matrix(c(0, 0, 1, 1, 0, 0), nrow = 1)
    kbl(a, format = "html", align = "c")
```

Which implies:

$$
\sum_i a_{(A)j} = 0 + 0 + 1 + 1 + 0 + 0 = 2
$$

And we know that $N = 6$, so that implies:

$$
\overline{a}_{(A)j} = \frac{\sum_i a_{Aj}}{N} = \frac{2}{6}=0.33
$$ The term $\overline{a}_{(k)j}$ is called the **row mean** for node *k* in the adjacency matrix. Just like we can compute row means, we can also compute **column means** by using the elements of the column vector $\overline{a}_{(k)i}$

Now that we know what the row means are, we can make sense of the term $(a_{(k)j} - \overline{a}_{(k)j})$ in @eq-cor. This is a vector composed of the *differences* between the row vector entries in the adjacency matrix and the row mean for that node. So in the case of node *A* and the row vector in @tbl-rowvecA that would imply:

```{r}
#| label: tbl-rowmeandiffA
#| tbl-cap: Row vector of mean differences for node A.
#| tbl-subcap:
#|   - "Vector of row entries minus the row mean."
#|   - "Result of subtracting row mean from row entries."
#| layout-ncol: 1

    a <- c(0, 0, 1, 1, 0, 0)
    b <- c("(0 - 0.33)", "(0 - 0.33)", "(1 - 0.33)", "(1 - 0.33)", "(0 - 0.33)", "(0 - 0.33)")
    c <- a - 0.33
    rm.1 <- matrix(b, nrow = 1)
    rm.2 <- matrix(c, nrow = 1)
    kbl(rm.1, format = "pipe", align = "c")
    kbl(rm.2, format = "pipe", align = "c")
```

Which implies: $$
\sum_j (a_{(k)j} - \overline{a}_{(k)j}) = -0.33 -0.33 + 0.67 + 0.67 -0.33 -0.33 = 0.02
$$

The numerator of @eq-cor, just says: "Take the entries in the row vector for the first node, and create a new vector composed of the those entries minus the row means and sum the vector. Then do the same for the other node and multiply the two numbers" And in the denominator of the equation we just square the same vectors sum them, multiply each of the two numbers and take the square root of the result product. Once we have the numerator and denominator we can evaluate the fraction and compute the correlation distance between those two nodes.

When we do that for each pair of nodes in @tbl-adjmat1, we end up with the **structural similarity matrix** shown in @tbl-cor, based on the correlation distance.

```{r}
#| label: tbl-cor
#| tbl-cap: Correlation distance matrix for an undirected graph.
#| tbl-cap-location: margin
 
    gr <- create_empty(6, directed = FALSE)
    gr <- gr %>% 
        bind_edges(data.frame(from = 1, to = 3:4)) %>% 
        bind_edges(data.frame(from = 2, to = 3:4)) %>% 
        bind_edges(data.frame(from = 3, to = 1:2)) %>% 
        bind_edges(data.frame(from = 4, to = 1:2)) %>% 
        bind_edges(data.frame(from = 5, to = 3:4)) %>% 
        bind_edges(data.frame(from = 6, to = 5)) %>% 
        mutate(name = toupper(letters[1:6]))
    gr <- simplify(gr)
    a <- matrix(as_adjacency_matrix(gr), nrow = length(V(gr)))
    rownames(a) <- V(gr)$name
    colnames(a) <- V(gr)$name
    a <- a[order(row.names(a)), order(row.names(a))]
    a <- corr.dist(a)
    c <- a
    diag(c) <- "--"
    kable(c, format = "pipe", padding = 2, align = "c") 
```

In @tbl-cor, the structurally equivalent pairs of nodes, *A* and *B* and *C* and *D* have $d^{corr} = 1.0$. Nodes that are completely non-equivalent like *C* and *E* and *D* and *E* have $d^{corr} = -1.0$. Nodes that are structurally similar, but not equivalent, like nodes *C* and *F* ($d^{corr} = 0.45$) get a positive number that is less than $1.0$.

## Iterated Correlational Distances: CONCOR
What happens if we were to try to use @eq-cor to find the *correlation distance of a correlation distance* matrix? If we were to do this and use @tbl-cor as our input matrix, we end up with @tbl-concor (a).

### We Need to go Deepah
Now, as Leo (when stuck in a dream, about a dream, about a dream...) always says: "We need to go deeper."^[[https://knowyourmeme.com/memes/we-need-to-go-deeper](https://knowyourmeme.com/memes/we-need-to-go-deeper)] And, indeed, we can. We can take the correlation distance of the nodes based on @tbl-concor-1. If we do that, we end up with the entries in @tbl-concor-2. If we keep on going, we end up with the entries in @tbl-concor-3. Note that in @tbl-concor-3, there are only two values for all the entries: $+1$ and $-1$!


```{r}
#| label: tbl-concor
#| tbl-cap: "Iterated correlation distances."
#| tbl-subcap:
#|   - "Second Iteration"
#|   - "Third Iteration"
#|   - "Fourth Iteration"
#| layout-ncol: 2
    b <- corr.dist(a)
    c <- corr.dist(b)
    d <- corr.dist(c)
    diag(b) <- "--"
    diag(c) <- "--"
    diag(d) <- "--"
    kbl(b, format = "pipe", align = "c") 
    kbl(c, format = "pipe", align = "c") 
    kbl(d, format = "pipe", align = "c") 
```

More importantly, as shown in @tbl-sepos, the structurally equivalent nodes have exactly the same pattern of $+1$s and $-1$s across the rows. This procedure of iterated correlations, invented by a team of sociologists and psychologists at Harvard University in the mid-1970s [@breiger75], is called **CONCOR**---and acronym for the hard to remember title of "**con**vergence of iterate **cor**relations''---and is designed to extract structurally equivalent positions from networks even when the input matrix is just based on structural similarities.

```{r}
#| label: tbl-sepos
#| tbl-cap: "Structurally Equivalent Positions in an undirected graph."
#| tbl-cap-location: margin

    kbl(d, format = "html", align = "c", padding = 2) %>% 
        row_spec(1:2, background = "salmon", bold = TRUE) %>%  
        row_spec(3:4, background = "lightgreen", bold = TRUE) %>% 
        row_spec(5, background = "cyan", bold = TRUE) %>% 
        row_spec(6, background = "violet", bold = TRUE) %>% 
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"))
```

## Blockmodeling
The example we considered previously concerns the relatively small network shown in @fig-equivex. What happens when we apply the method of iterated correlations (CONCOR) to a bigger network, something like the one shown in @fig-eigen?

```{r}
#| label: fig-eigen
#| fig-cap: "An undirected graph."
#| fig-cap-location: margin
#| fig-width: 12
#| fig-height: 12

    fr <- c(rep(1, 5), rep(2, 5), rep(3, 5), rep(4, 3), rep(20, 3))
    to <- c(5:9, 10:14, 15:19, 1:3, 5, 21, 22)
    edge.dat <- data.frame(fr, to)
    node.dat <- data.frame(name = toupper(letters[union(fr, to)]))
    gr <- tbl_graph(edges = edge.dat, nodes = node.dat, directed = FALSE)
    gr <- as_tbl_graph(simplify(gr)) 
    p <- ggraph(gr, layout = 'kk') 
    p <- p + geom_edge_link(color = "steelblue", width = 1.15) 
    p <- p + geom_node_point(aes(x = x, y = y), color = "tan2", size = 22)
    p <- p + geom_node_text(aes(label = name), size = 10, color = "white")
    p <- p + theme_graph()
    p
```

Well, we can begin by computing the correlation distance across all ,the $V=22$ nodes in that network using @eq-cor. The result of that looks like @tbl-blocks-1. Note that even before we do any iterated correlations of correlation matrices we can see that the peripheral, single-connection nodes $E, F, G, H$, $I, J, K, L, M$ and $N, O, P, Q, R$ are perfectly structurally equivalent. This makes sense, because all the nodes in each of these three groups have identical neighborhoods, since they happen to be connected to the same central node $A$ for the first group, $B$ for the second group and $C$ for the third group. Note also that $U$ and $V$ are structurally equivalent, since their neighborhoods are the same: Their single connection is to node $S$.

```{r}
#| label: tbl-blocks
#| tbl-cap: "Correlation Distance Matrices Corresponding to an Undirected Graph." 
#| tbl-subcap:
#|   - "Original Correlation Distance Matrix."
#|   - "Original Correlation Distance Matrix After Ten Iterations."
#|   - "Correlation Distance Matrix in (a) with Rows and Columns Reshuffled to Show Hidden Pattern." 
#| tbl-cap-location: bottom
#| layout-ncol: 1
    a <- matrix(as_adjacency_matrix(gr), nrow = length(V(gr)))
    rownames(a) <- V(gr)$name
    colnames(a) <- V(gr)$name
    
    b <- corr.dist(a)
    c <- b
    k <- 1
    while (mean(abs(c)) != 1) {
      c <- corr.dist(c)
      k <- k + 1
      }
    kbl(b, align = "c", format = "html", full_width = TRUE) %>% 
      column_spec(1, bold = TRUE) %>% 
      kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>% 
      scroll_box(width = "57%")
    kbl(c, align = "c", format = "html", full_width = TRUE) %>% 
      column_spec(1, bold = TRUE) %>% 
      kable_styling(full_width = TRUE,
                    bootstrap_options = c("striped", "hover", "condensed", "responsive"))
    rs <- corrMatOrder(c, order = "hclust")
    d <- c[rs, rs]
     kbl(d, align = "c", format = "html", full_width = TRUE) %>% 
      column_spec(1, bold = TRUE) %>% 
      kable_styling(full_width = TRUE,
                    bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>% 
      row_spec(11, extra_css = "border-bottom: 2px solid;") %>%  
      column_spec(12, extra_css = "border-right: 2px solid;")
```

What happens when we take the correlation distance of the correlation distance matrix shown in @tbl-blocks-1, and the correlation distance of the resulting matrix, and keep going until we only have zeros and ones? The results is @tbl-blocks-2. This matrix seems to reveal a much deeper pattern of commonalities in structural positions across the nodes in @fig-eigen. In fact, if we were a conspiracy theorist like Charlie from *Always Sunny in Philadelphia*, we might even surmise that there is a *secret pattern* that can be revealed if we reshuffled the rows and the columns of the matrix (without changing any of the numbers of course!).^[[https://knowyourmeme.com/memes/pepe-silvia](https://knowyourmeme.com/memes/pepe-silvia)]

If we do that, we end up with @tbl-blocks-3. So it turns out that there is indeed a secret pattern! The reshuffling shows that the nodes in the network can be divided into two **blocks** such *within* blocks all nodes are structurally similar (and some structurally equivalent) and *across* blocks, all nodes are structurally dissimilar. Thus $V, U, S, H, G, F, E, T, C, A, B$ are members of one structurally similar block (let's called them "Block 1"), and nodes $R, Q, P, O, N, M, L, K, J, D, I$ are members of another structurally similar block (let's called them "Block 2"). Nodes in "Block 1" are structurally dissimilar from nodes in "Block 2," but structurally similar to one another and vice versa. To illustrate, @fig-blocks1 is the same as @fig-eigen, but this time nodes are colored by their memberships in two separate blocks.

```{r}
#| label: fig-blocks1
#| fig-cap: "An undirected graph with block membership indicated by node color."
#| fig-cap-location: margin
#| fig-width: 12
#| fig-height: 12

    node.color <- c(rep("firebrick",3), "darkblue", "firebrick", rep("firebrick", 4), rep("darkblue", 10), "firebrick", rep("firebrick", 2))
    p <- ggraph(gr, layout = 'kk') 
    p <- p + geom_edge_link(color = "steelblue", width = 1.15) 
    p <- p + geom_node_point(aes(x = x, y = y), color = node.color, size = 22)
    p <- p + geom_node_text(aes(label = name), size = 10, color = "white")
    p <- p + theme_graph()
    p
```

Note that we haven't changed any of the information in @tbl-blocks-2 to get @tbl-blocks-3. If you check, the row and column entries for each node in both figures are identical. It's just that we changed the way the rows ordered vertically and the way the columns are ordered horizontally. For instance, node $A$'s pattern of connections is negatively correlated with node $I$'s in @tbl-blocks-2, and has the same negative correlation entry in @tbl-blocks-3. The same goes for each one of node $A$'s other correlations, and the same for each node in the table. @tbl-blocks-2 and @tbl-blocks-3 contain the *same* information it's just that @tbl-blocks-3 makes it easier to see a hidden pattern.

This property of the method of iterated correlations is the basis of a strategy for uncovering blocks of structurally similar actors in a network developed by a team of sociologists, physicists, and mathematicians working at Harvard in the 1970s. The technique is called **blockmodeling** [@white76]. Let's see how it works.

### We Need to go Deepah
Of course, as Leo always says: "We need to go deeper." And indeed we can. What happens if we do the same analysis as above, but this time in the two **node-induced subgraphs** defined by the set of structurally similar nodes in each of the two blocks we uncovered in the original graph? Then we get @tbl-blocks2-1 and @tbl-blocks2-2.

```{r}
#| label: tbl-blocks2
#| tbl-cap: "Subgraph Blockmodels" 
#| tbl-subcap:
#|   - "Blockmodel of a subgraph."
#|   - "Another Blockmodel of another subgraph"
#| layout-ncol: 1

    b1 <- b[rs[1:11], rs[1:11]]
    b2 <- b[rs[12:22], rs[12:22]]
    
    c1 <- b1
    while (mean(abs(c1)) != 1) {
      c1 <- corr.dist(c1)
      }
    
    c2 <- b2
    while (mean(abs(c2[c2 != 0])) != 1) {
      c2 <- corr.dist(c2)
      }
    rs1 <- corrMatOrder(c1, order = "hclust")
    d1 <- c1[rs1, rs1]
    
    rs2 <- corrMatOrder(c2, order = "hclust")
    d2 <- c2[rs2, rs2]
    kbl(d1, align = "c", format = "html", full_width = TRUE) %>%
    column_spec(1, bold = TRUE) %>% 
    kable_styling(full_width = TRUE,
                  bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>% 
      row_spec(6, extra_css = "border-bottom: 2px solid;") %>%  
      column_spec(7, extra_css = "border-right: 2px solid;")
    
    kbl(d2, align = "c", format = "html", full_width = TRUE) %>%
    column_spec(1, bold = TRUE) %>% 
    kable_styling(full_width = TRUE,
                  bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>% 
      row_spec(6, extra_css = "border-top: 2px solid;") %>% 
      row_spec(6, extra_css = "border-bottom: 2px solid;") %>%  
      column_spec(7, extra_css = "border-right: 2px solid;") %>% 
      column_spec(7, extra_css = "border-left: 2px solid;") 
      
```

We can see that @tbl-blocks-1 separates our original Block 1 into two further **sub-blocks**. Let's call them "Block 1a" and "Block 1b." Block 1a is composed of nodes $A, B, C, S, U, V$ and Block 1b is composed of nodes $E, F, G, H, T$. @tbl-blocks-2 separates our original Block 2 into *three* further sub-blocks. There's the block composed of nodes $I, J, K, L, M$. Let's call this "Block 2a", the block composed of nodes $N, O, P, Q, R$. Let's call this "Block 2b." Then, there's node $D$. Note that this node is only structurally similar to itself and is neither similar nor dissimilar to the other nodes in the subgraph $d^{corr} = 0$, so it occupies a position all by itself! Let's call it "Block 2c."

```{r}
#| label: tbl-blocks3
#| tbl-cap: "Subgraph Blockmodels" 
#| tbl-subcap:
#|   - "Blockmodel of a subgraph."
#|   - "Another Blockmodel of another subgraph"
#| layout-ncol: 2

    n <- c("B", "A", "C", "S", "V", "U")
    b3 <- b[n, n]

    c3 <- b3
    while (mean(abs(c3)) != 1) {
      c3 <- corr.dist(c3)
    }
    rs3 <- corrMatOrder(c3, order = "hclust")
    d3 <- c3[rs3, rs3]
    
    
    n <- c("B", "A", "C", "S")
    b4 <- b[n, n]
    c4 <- b4
    while (mean(abs(c4)) != 1) {
      c4 <- corr.dist(c4)
    }
    rs4 <- corrMatOrder(c4, order = "hclust")
    d4 <- c4[rs4, rs4]
    
    kbl(d3, align = "c", format = "html", full_width = TRUE) %>%
    column_spec(1, bold = TRUE) %>% 
    kable_styling(full_width = TRUE,
                  bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>% 
      row_spec(4, extra_css = "border-bottom: 2px solid;") %>%  
      column_spec(5, extra_css = "border-right: 2px solid;")
    
    kbl(d4, align = "c", format = "html", full_width = TRUE) %>%
    column_spec(1, bold = TRUE) %>% 
    row_spec(2, extra_css = "border-bottom: 2px solid;") %>%  
    column_spec(3, extra_css = "border-right: 2px solid;") %>% 
    kable_styling(full_width = TRUE,
                  bootstrap_options = c("striped", "hover", "condensed", "responsive"))
```

Now let's do a couple of final splits of the subgraph composed of nodes $A, B, C, S, U, V$. This is shown in @tbl-blocks3. The first split separates nodes in block $A, B, C, S$ from those in block $U, V$ (@tbl-blocks3-1). The second splits the nodes in subgraph $A, B, C, S$ into two blocks composed of $A, S$ and  $B, C$, respectively (@tbl-blocks3-2). 

```{r}
#| label: fig-blocks2
#| fig-cap: "An undirected graph with block membership indicated by node color."
#| fig-cap-location: margin
#| fig-width: 12
#| fig-height: 12

    node.color <- c("firebrick", rep("darkblue", 2), "purple", rep("tan1", 5), rep("darkgreen", 5), rep("#CC79A7", 5), "firebrick", rep("#56B4E9", 2))
    p <- ggraph(gr, layout = 'kk') 
    p <- p + geom_edge_link(color = "steelblue", width = 1.15) 
    p <- p + geom_node_point(aes(x = x, y = y), color = node.color, size = 22)
    p <- p + geom_node_text(aes(label = name), size = 10, color = "white")
    p <- p + theme_graph()
    p
```

@fig-blocks2 shows the nodes in @fig-eigen colored according to our final block partition. It is clear that the blockmodeling approach captures patterns of structural similarity. For instance, all the single-connection nodes connected to more central nodes get assigned to their own position: Block 1b: $E, F, G, H, T$, Block 2a: $I, J, K, L, M$, and Block 2b: $N, O, P, Q, R$. The most central node $D$ (in terms of Eigenvector centrality) occupies a unique position in the graph. Two of the three central nodes (in terms of degree centrality) $B, C$ get assigned to their own position. Meanwhile $A, S$ form their own structurally similar block. Finally, $U, V$ also form their own structurally similar block as both are structurally equivalent in the orignal graph. 

### The Blocked Adjancency Matrix
What happens if we were to go back fo the **adjacency matrix** corresponding to @fig-eigen, and then reshuffle the rows and columns to correspond to all these wonderful blocks we have uncovered? Well, we would en up with something like @tbl-blocked. This is called the **blocked adjacency matrix**. In the blocked adjacency matrix, the division between the nodes corresponding to each block of structurally similar nodes in @tbl-blocks2 and @tbl-blocks3 is marked by thick black lines going across the rows and columns.

Each diagonal rectangle in @tbl-blocked corresponds to **within-block** connections. Each off-diagonal rectangle corresponds to **between block** connections. There are two kinds of rectangles in the blocked adjacency matrix. First, there are rectangles that only contains zero entries. These are called **zero blocks**. For instance the top-left rectangle in @tbl-blocked is a zero block. Then there rectangles that have some non-zero entries in them (ones, since this is a binary adjacency matrix). These are called **one blocks**. For instance, the fourth rectangle going down the rows (corresponding to the block that nodes $B, C$ belong to) is a one block. 

```{r}
#| label: tbl-blocked
#| tbl-cap: "Blocked adjancency matrix."
#| tbl-cap-location: margin

    a <- matrix(as_adjacency_matrix(gr), nrow = length(V(gr)))
    rownames(a) <- V(gr)$name
    colnames(a) <- V(gr)$name
    final.blocks <- c("I", "J", "K", "L", "M", "N", "O", "P", "Q", "R", "T", "E", "F", "G", "H", "B", "C", "A", "S", "U", "V", "D")
    b <- a[final.blocks, final.blocks]
    kbl(b, align = "c", format = "html", full_width = TRUE) %>%        column_spec(1, bold = TRUE) %>% 
      kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>% 
      row_spec(5, extra_css = "border-bottom: 2px solid;") %>%  
      row_spec(10, extra_css = "border-bottom: 2px solid;") %>%  
      row_spec(15, extra_css = "border-bottom: 2px solid;") %>%  
      row_spec(17, extra_css = "border-bottom: 2px solid;")  %>% 
      row_spec(19, extra_css = "border-bottom: 2px solid;")  %>% 
      row_spec(21, extra_css = "border-bottom: 2px solid;") %>% 
      column_spec(6, extra_css = "border-right: 2px solid;") %>% 
      column_spec(11, extra_css = "border-right: 2px solid;") %>%  
      column_spec(16, extra_css = "border-right: 2px solid;") %>%  
      column_spec(18, extra_css = "border-right: 2px solid;") %>%  
      column_spec(20, extra_css = "border-right: 2px solid;") %>% 
      column_spec(22, extra_css = "border-right: 2px solid;")  
```

Zero-blocks indicate that the members of the row block don't have any connections with the members the column block (which can include themselves!). For instance, the zero-block in the top-left corner of the blocked adjacency matrix in @tbl-blocked indicates that the members of this block are not connected to one another in the network (and we can verify from @fig-blocks2 that this is indeed the case).

One blocks indicate that the members of the column block share some connections with the members of the column block (which can also include themselves!). For instance, the one-block in the fourth rectangle going down the rows (corresponding to the block that nodes $B, C$ belong to) tells us that members of this block are connected to at least one member of the $I, J, K, L, M$ block (and we can verify from @fig-blocks2 that this is indeed the case, since $B$ is connected to all of them). 

### The Image Matrix
From this reshuffled adjacency matrix, we can get to a **reduced image matrix** containing the relations not between the nodes in the graph, but *between the blocks in the graph*. The way we proceed to construct the image matrix is as follows: 

- First we create an empty matrix $\mathbf{B}$ of dimensions $b \times b$ where $B$ is the number of blocks in the blockmodel. In our example, $b = 7$ so the image matrix has seven rows and seven columns. The $ij^{th}$ cell in the image matrix $\mathbf{B}$ records the relationship between row block *i* and column block *j* in the blockmodel.

- Second, we put a *zero* in the image matrix if the rectangle corresponding to the relationship between blocks *i* and *j* in @tbl-blocked is a **zero-block**.

- Third, we put a *one* in the image matrix if the rectangle corresponding to the relationship between blocks *i* and *j* in @tbl-blocked is a **one-block**.

The result is @tbl-image.

```{r}
#| label: tbl-image
#| tbl-cap: "Image matrix Corresponding to the blockmodel of an Undirected Graph."
#| tbl-cap-location: margin

  c <- matrix(c(0, 0, 0, 1, 0, 0, 0,
                0, 0, 0, 1, 0, 0, 0,
                0, 0, 0, 0, 1, 0, 0,
                1, 1, 0, 0, 0, 0, 1,
                0, 0, 1, 0, 0, 1, 1,
                0, 0, 0, 0, 1, 0, 0,
                0, 0, 0, 1, 1, 0, 0), 
              nrow = 7)
  rownames(c) <- c("I, J, K, L", "N, O, P, Q, R", "T, E, F, G, H", "B, C", "A, S", "U, V", "D")
  colnames(c) <- c("I, J, K, L", "N, O, P, Q, R", "T, E, F, G, H", "B, C", "A, S", "U, V", "D")
    kbl(c, align = "c", format = "html") %>% 
      column_spec(1, bold = TRUE) %>% 
      kable_styling(full_width = TRUE,
                    bootstrap_options = c("striped", "hover", "condensed", "responsive"))
```

So the big blocked adjacency matrix in @tbl-blocks-3 can be reduced to the **image matrix** shown @tbl-image, summarizing the relations between the blocks in the graph. This matrix, can then even be represented as a graph, so that we can see the pattern of relations between blocks! This is shown in @fig-blocks3 

```{r}
#| label: fig-blocks3
#| fig-cap: Graph representation of reduced image matrix from a blockmodel.
#| fig-cap-location: margin
#| fig-width: 12
#| fig-height: 10

    gr <- graph_from_adjacency_matrix(c) %>% 
      as_tbl_graph() %>% 
      activate(nodes) %>% 
      mutate(names =  c("I, J, K, L", "N, O, P, Q, R", "T, E, F, G, H", "B, C", "A, S", "U, V", "D"))
    p <- ggraph(gr, layout = 'tree') 
    p <- p + geom_edge_link(color = "steelblue", width = 1.15) 
    p <- p + geom_node_label(aes(label = names), size = c(5, 5, 5, 7, 7, 5, 10))

    p <- p + theme_graph()
    p
```


This is how **blockmodeling** works!

## References {.unnumbered}
